{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "\n",
        "AWS_ACCESS_KEY_ID = userdata.get('AWS_ACCESS_KEY_ID')\n",
        "AWS_SECRET_ACCESS_KEY = userdata.get('AWS_SECRET_ACCESS_KEY')\n",
        "AWS_REGION = userdata.get('AWS_REGION')"
      ],
      "metadata": {
        "id": "EmiK539203t2"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "sL_hi8tZqPWc"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "from datetime import datetime\n",
        "import yfinance as yf\n",
        "from io import BytesIO"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def data_extraction(ticker):\n",
        "  try:\n",
        "    print(f\"Extracting data for {ticker} ...\")\n",
        "    asset = yf.Ticker(ticker)\n",
        "    data = asset.info\n",
        "\n",
        "    if not data:\n",
        "      print(f\"No data found for {ticker}\")\n",
        "      return None\n",
        "\n",
        "    data['download_timestamp'] = datetime.now().isoformat()\n",
        "    return data\n",
        "\n",
        "  except Exception as e:\n",
        "    print(f\"Error at data extraction: {e}\")\n",
        "    return None"
      ],
      "metadata": {
        "id": "gbMvQx1_rgOK"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install boto3 -q\n",
        "import boto3"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ncT-yLbSSBPh",
        "outputId": "c07ee83b-917c-469c-e061-34210aa966ee"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/140.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m140.6/140.6 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.6/14.6 MB\u001b[0m \u001b[31m73.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def s3_data_load(data, ticker):\n",
        "  s3 = boto3.resource(\n",
        "      service_name = 's3',\n",
        "      region_name = AWS_REGION,\n",
        "      aws_access_key_id = AWS_ACCESS_KEY_ID,\n",
        "      aws_secret_access_key = AWS_SECRET_ACCESS_KEY\n",
        "  ) # resources for s3 connection\n",
        "\n",
        "  # path configs\n",
        "  bucket_name = 'stock-market-monitoring'\n",
        "  now = datetime.now()\n",
        "  partition_date = now.strftime('%Y-%m-%d')\n",
        "  timestamp = now.strftime('%H%M%S')\n",
        "\n",
        "  file_path = f'bronze/yahoo_finance/ticker={ticker}/extraction_date={partition_date}/{timestamp}.json'\n",
        "\n",
        "  try:\n",
        "    json_data = json.dumps(data, ensure_ascii=False).encode('utf-8') # transform data into json file\n",
        "\n",
        "    s3.Object(bucket_name, file_path).put(Body=json_data) # load data into s3\n",
        "\n",
        "    print(f\"Upload Done: s3://{bucket_name}/{file_path}\")\n",
        "    return file_path\n",
        "  except Exception as e:\n",
        "    print(f\"Error at S3 upload: {e}\")\n",
        "    return None"
      ],
      "metadata": {
        "id": "_Ho_kQu0xhF5"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ticker_list = ['AAPL', 'MSFT', 'GOOGL', 'AMZN', 'META', 'TSLA', 'NVDA', 'NFLX', 'TSM']\n",
        "\n",
        "def run_full_ingestion(ticker_list):\n",
        "  print(f'Initializing data ingestion of {len(ticker_list)} assets ...')\n",
        "\n",
        "  for ticker in ticker_list:\n",
        "    try:\n",
        "      data = data_extraction(ticker)\n",
        "      if data:\n",
        "        s3_data_load(data, ticker)\n",
        "        print(f'{ticker} assets loaded')\n",
        "    except Exception as e:\n",
        "      print(f'Error at {ticker}: {e}')\n",
        "      continue\n",
        "  print('Ingestion completed')"
      ],
      "metadata": {
        "id": "VkzqxjcyIo1S"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Execution\n",
        "if __name__ == '__main__':\n",
        "  run_full_ingestion(ticker_list)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PbnZLjyW4S4A",
        "outputId": "cba62750-04eb-4e64-c8e7-97acb29f9e7d"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initializing data ingestion of 9 assets ...\n",
            "Extracting data for AAPL ...\n",
            "Upload Done: s3://stock-market-monitoring/bronze/yahoo_finance/ticker=AAPL/extraction_date=2026-01-16/202729.json\n",
            "AAPL assets loaded\n",
            "Extracting data for MSFT ...\n",
            "Upload Done: s3://stock-market-monitoring/bronze/yahoo_finance/ticker=MSFT/extraction_date=2026-01-16/202730.json\n",
            "MSFT assets loaded\n",
            "Extracting data for GOOGL ...\n",
            "Upload Done: s3://stock-market-monitoring/bronze/yahoo_finance/ticker=GOOGL/extraction_date=2026-01-16/202731.json\n",
            "GOOGL assets loaded\n",
            "Extracting data for AMZN ...\n",
            "Upload Done: s3://stock-market-monitoring/bronze/yahoo_finance/ticker=AMZN/extraction_date=2026-01-16/202732.json\n",
            "AMZN assets loaded\n",
            "Extracting data for META ...\n",
            "Upload Done: s3://stock-market-monitoring/bronze/yahoo_finance/ticker=META/extraction_date=2026-01-16/202734.json\n",
            "META assets loaded\n",
            "Extracting data for TSLA ...\n",
            "Upload Done: s3://stock-market-monitoring/bronze/yahoo_finance/ticker=TSLA/extraction_date=2026-01-16/202735.json\n",
            "TSLA assets loaded\n",
            "Extracting data for NVDA ...\n",
            "Upload Done: s3://stock-market-monitoring/bronze/yahoo_finance/ticker=NVDA/extraction_date=2026-01-16/202737.json\n",
            "NVDA assets loaded\n",
            "Extracting data for NFLX ...\n",
            "Upload Done: s3://stock-market-monitoring/bronze/yahoo_finance/ticker=NFLX/extraction_date=2026-01-16/202738.json\n",
            "NFLX assets loaded\n",
            "Extracting data for TSM ...\n",
            "Upload Done: s3://stock-market-monitoring/bronze/yahoo_finance/ticker=TSM/extraction_date=2026-01-16/202739.json\n",
            "TSM assets loaded\n",
            "Ingestion completed\n"
          ]
        }
      ]
    }
  ]
}