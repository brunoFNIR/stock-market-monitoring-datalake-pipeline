# ğŸ’¹ Stock Market Data Lakehouse: Medallion Architecture on AWS

Este repositÃ³rio contÃ©m um pipeline de dados completo para monitoramento de ativos financeiros, estruturado sob os princÃ­pios de um **Data Lakehouse** utilizando a **Arquitetura MedalhÃ£o** (Bronze, Silver e Gold).

---

## ğŸŒ Idiomas / Languages
- [**PortuguÃªs (Brasil)**](#-portuguÃªs-brasil)
- [**English**](#-english)

---

## ğŸ‡§ğŸ‡· PortuguÃªs (Brasil)

### ğŸ“ DescriÃ§Ã£o do Projeto
O objetivo deste projeto Ã© extrair dados reais da API Yahoo Finance, processÃ¡-los via Python e armazenÃ¡-los de forma estruturada no AWS S3. O pipeline demonstra prÃ¡ticas avanÃ§adas de engenharia de dados, como o uso de formatos colunares (Parquet) para otimizaÃ§Ã£o de custos e performance em nuvem.

### ğŸ—ï¸ Arquitetura do Sistema
![Arquitetura do Sistema](./docs/assets/images/data_lakehouse_medallion_architecture.png)

### ğŸ› ï¸ Camadas de Dados
* **Bronze (Raw):** IngestÃ£o de dados brutos em formato JSON via `yfinance`. Os arquivos sÃ£o particionados por `ticker` e `extraction_date`, garantindo a rastreabilidade da fonte original.
* **Silver (Staging):** Limpeza de dados e mapeamento de schema. ConversÃ£o de JSON para **Apache Parquet com compressÃ£o Snappy**, otimizando o armazenamento e a velocidade de leitura.
* **Gold (Analytics):** ConsolidaÃ§Ã£o dos dados. AplicaÃ§Ã£o de lÃ³gica de ranking por Market Cap e cÃ¡lculo de mÃ©tricas de valorizaÃ§Ã£o (*Upside Potential*). Dados prontos para consumo por ferramentas de BI.

### ğŸ§° Tecnologias Utilizadas
| Tecnologia | FunÃ§Ã£o |
| :--- | :--- |
| **Python** | Linguagem principal e lÃ³gica de ETL. |
| **Pandas** | ManipulaÃ§Ã£o e transformaÃ§Ã£o de dados. |
| **Boto3** | SDK oficial da AWS para integraÃ§Ã£o com S3. |
| **AWS S3** | Armazenamento de objetos (Data Lake). |
| **Google Colab** | Ambiente de desenvolvimento e execuÃ§Ã£o. |
| **Apache Parquet** | Formato de armazenamento colunar otimizado. |

### âš™ï¸ ConfiguraÃ§Ã£o
O projeto utiliza segredos do Google Colab para seguranÃ§a. Configure as seguintes variÃ¡veis:
- `AWS_ACCESS_KEY_ID`
- `AWS_SECRET_ACCESS_KEY`
- `AWS_REGION`

### ğŸš€ PrÃ³ximos Passos
* Implementar orquestraÃ§Ã£o via **AWS Lambda** ou **Apache Airflow**.
* Configurar **AWS Athena** para consultas SQL diretamente no S3.
* Criar dashboards no **Amazon QuickSight** ou PowerBI.

---

## ğŸ‡ºğŸ‡¸ English

### ğŸ“ Project Description
This project implements a robust data pipeline for financial asset monitoring, using a **Medallion Architecture** (Bronze, Silver, and Gold). It extracts real-time data from the Yahoo Finance API, processes it through Python, and stores it in an AWS S3-based **Data Lakehouse**.

### ğŸ—ï¸ System Architecture
![System Architecture](./docs/assets/images/data_lakehouse_medallion_architecture.png)

### ğŸ› ï¸ Data Layers
* **Bronze (Raw):** Raw data ingestion in JSON format using `yfinance`. Files are partitioned by `ticker` and `extraction_date` for full traceability.
* **Silver (Staging):** Data cleaning and schema mapping. Conversion from JSON to **Apache Parquet with Snappy compression** for cost-effective storage and high-performance querying.
* **Gold (Analytics):** Business logic layer. Includes data consolidation, Market Cap ranking, and *Upside Potential* metrics. Data is ready for BI consumption.

### ğŸ§° Tech Stack
| Technology | Role |
| :--- | :--- |
| **Python** | Core ETL logic and processing. |
| **Pandas** | Data manipulation and transformation. |
| **Boto3** | AWS SDK for S3 integration. |
| **AWS S3** | Cloud Object Storage (Data Lake). |
| **Google Colab** | Development and execution environment. |
| **Apache Parquet** | Optimized columnar storage format. |

### âš™ï¸ Configuration
The project uses Google Colab secrets. Set up the following variables:
- `AWS_ACCESS_KEY_ID`
- `AWS_SECRET_ACCESS_KEY`
- `AWS_REGION`

### ğŸš€ Next Steps
* Automate orchestration using **AWS Lambda** or **Apache Airflow**.
* Enable **AWS Athena** for SQL queries on top of the S3 Gold layer.
* Build visual dashboards with **Amazon QuickSight** or PowerBI.
