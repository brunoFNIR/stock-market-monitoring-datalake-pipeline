# -*- coding: utf-8 -*-
"""01_data_ingestion_yf_bronze.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1J7nTHyRQX4tuLwZxaFjPwdPHVnLNw-q9
"""

from google.colab import userdata

AWS_ACCESS_KEY_ID = userdata.get('AWS_ACCESS_KEY_ID')
AWS_SECRET_ACCESS_KEY = userdata.get('AWS_SECRET_ACCESS_KEY')
AWS_REGION = userdata.get('AWS_REGION')

import json
from datetime import datetime
import yfinance as yf
from io import BytesIO

def data_extraction(ticker):
  try:
    print(f"Extracting data for {ticker} ...")
    asset = yf.Ticker(ticker)
    data = asset.info

    if not data:
      print(f"No data found for {ticker}")
      return None

    data['download_timestamp'] = datetime.now().isoformat()
    return data

  except Exception as e:
    print(f"Error at data extraction: {e}")
    return None

!pip install boto3 -q
import boto3

def s3_data_load(data, ticker):
  s3 = boto3.resource(
      service_name = 's3',
      region_name = AWS_REGION,
      aws_access_key_id = AWS_ACCESS_KEY_ID,
      aws_secret_access_key = AWS_SECRET_ACCESS_KEY
  ) # resources for s3 connection

  # path configs
  bucket_name = 'stock-market-monitoring'
  now = datetime.now()
  partition_date = now.strftime('%Y-%m-%d')
  timestamp = now.strftime('%H%M%S')

  file_path = f'bronze/yahoo_finance/ticker={ticker}/extraction_date={partition_date}/{timestamp}.json'

  try:
    json_data = json.dumps(data, ensure_ascii=False).encode('utf-8') # transform data into json file

    s3.Object(bucket_name, file_path).put(Body=json_data) # load data into s3

    print(f"Upload Done: s3://{bucket_name}/{file_path}")
    return file_path
  except Exception as e:
    print(f"Error at S3 upload: {e}")
    return None

ticker_list = ['AAPL', 'MSFT', 'GOOGL', 'AMZN', 'META', 'TSLA', 'NVDA', 'NFLX', 'TSM']

def run_full_ingestion(ticker_list):
  print(f'Initializing data ingestion of {len(ticker_list)} assets ...')

  for ticker in ticker_list:
    try:
      data = data_extraction(ticker)
      if data:
        s3_data_load(data, ticker)
        print(f'{ticker} assets loaded')
    except Exception as e:
      print(f'Error at {ticker}: {e}')
      continue
  print('Ingestion completed')

# Execution
if __name__ == '__main__':
  run_full_ingestion(ticker_list)